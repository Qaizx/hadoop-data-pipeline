# FROM apache/airflow:2.9.1-python3.12

# USER root
# RUN apt-get update && apt-get install -y docker.io

# USER airflow

# RUN pip install --no-cache-dir \
#     apache-airflow-providers-apache-spark \
#     --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.1/constraints-3.12.txt"


FROM apache/airflow:2.9.1

USER root

RUN apt-get update && \
    apt-get install -y openjdk-17-jre-headless wget && \
    wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz && \
    tar -xzf hadoop-3.3.6.tar.gz -C /opt && \
    mv /opt/hadoop-3.3.6 /opt/hadoop && \
    rm hadoop-3.3.6.tar.gz && \
    apt-get clean

ENV HADOOP_HOME=/opt/hadoop
ENV PATH=$PATH:/opt/hadoop/bin

USER airflow

RUN pip install --no-cache-dir apache-airflow-providers-apache-spark --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.1/constraints-3.12.txt"
